{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/as685989/Github/cyclone-research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import case metadata for each basin\n",
    "wnp_metadata = pd.read_csv('subset_cyclones/wnp_era5_metadata.txt', sep = '\\t')\n",
    "atl_metadata = pd.read_csv('subset_cyclones/atl_era5_metadata.txt', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing function to mimic NCL's join feature\n",
    "def preproc(ds):\n",
    "    da_new_time = xr.DataArray(np.array([0]), coords=[np.array([0])], dims='new_time')\n",
    "    ds = ds.expand_dims('new_time').assign_coords(new_time=da_new_time).drop('time').squeeze('time').rename({'new_time': 'time'})    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a multifile xarray Dataset\n",
    "dir_wnp = './ERA5_data/wnp/wnp_relative/' #Specify the directory containing file(s) of interest\\\n",
    "dir_atl = './ERA5_data/atl/atl_relative/'\n",
    "\n",
    "DS_wnp = xr.open_mfdataset(dir_wnp+'wnp_*_rel.nc', preprocess = preproc,\n",
    "                           combine = 'nested', concat_dim = 'case')\n",
    "DS_wnp = DS_wnp.assign_coords(case=np.array(wnp_metadata['wnp_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS_atl = xr.open_mfdataset(dir_atl+'atl_*_rel.nc', preprocess = preproc,\n",
    "                           combine = 'nested', concat_dim = 'case')\n",
    "DS_atl = DS_atl.assign_coords(case=np.array(atl_metadata['atl_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the geopotential variable\n",
    "z_wnp = DS_wnp.z\n",
    "z_atl = DS_atl.z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a function to perform more preprocessing\n",
    "def to_gph(da):\n",
    "    gph = da/9.80665 #Convert geopotential to geopotential height\n",
    "    gph.attrs['units'] = 'gpm'\n",
    "    gph.attrs['long_name'] = '500 hPa Geopotential Height'\n",
    "    return gph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gph_wnp = to_gph(z_wnp)\n",
    "gph_atl = to_gph(z_atl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weight the data based on latitude\n",
    "def apply_weights(da):\n",
    "    weight_arr = np.sqrt(np.cos(np.radians(da.latitude))) #sqrt of the cosine of the latitude in radians\n",
    "    da_weighted = da * weight_arr #Apply the weights\n",
    "    da_weighted.attrs = da.attrs #Copy attributes onto the weighted array\n",
    "    return da_weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform sqrt cos latitude weighting\n",
    "gph_wnp_weighted = apply_weights(gph_wnp)\n",
    "gph_atl_weighted = apply_weights(gph_atl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to extract a 4D numpy array of just the data values and\n",
    "#reshape it so that it contains one flattened array for each case.\n",
    "#Each case, once flattended, is 121*481, or 58,201 values\n",
    "\n",
    "def to_input(da):\n",
    "    input_values = da.values #Extract a 4D (case, time, latitude, longitude) numpy array of just the data values\n",
    "    input_arr = input_values.reshape((input_values.shape[0], 58201)) #Reshape so that the input contains one flattened array for each case\n",
    "    return input_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnp_input = to_input(gph_wnp_weighted)\n",
    "atl_input = to_input(gph_atl_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3555.8125\n",
      "3555.8125\n"
     ]
    }
   ],
   "source": [
    "#Verify the structure of the input array is as expected\n",
    "input_arr = wnp_input[300,2]\n",
    "original_arr = gph_wnp_weighted.isel(case = 300, time = 0, latitude = 0, longitude = 2).values\n",
    "print(input_arr, '\\n', original_arr, sep = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize and xarray Dataset to hold the preprocessed data\n",
    "ds_wnp_input = xr.Dataset(coords = {'case': np.array(wnp_metadata['wnp_id'])})\n",
    "ds_atl_input = xr.Dataset(coords = {'case': np.array(atl_metadata['atl_id'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Place the preprocessed data into the xarray Dataset\n",
    "ds_wnp_input['gph']=(['case', 'values'], wnp_input)\n",
    "ds_atl_input['gph']=(['case', 'values'], atl_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add some attributes\n",
    "history = 'Values are weighted by the sqrt of the cos of the latitude'\n",
    "ds_wnp_input.attrs['history'] = history\n",
    "ds_atl_input.attrs['history'] = history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (case: 601, values: 58201)\n",
       "Coordinates:\n",
       "  * case     (case) object 'atl_001' 'atl_002' 'atl_003' ... 'atl_600' 'atl_601'\n",
       "Dimensions without coordinates: values\n",
       "Data variables:\n",
       "    gph      (case, values) float32 3661.766 3662.651 ... 5309.957 5314.8633\n",
       "Attributes:\n",
       "    history:  Values are weighted by the sqrt of the cos of the latitude"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verify the Dataset to be output looks as expected\n",
    "ds_atl_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_wnp_input.to_netcdf('som/wnp_som_input.nc')\n",
    "ds_atl_input.to_netcdf('som/atl_som_input.nc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
